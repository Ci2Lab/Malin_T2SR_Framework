{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe71e70-9846-4e44-abf3-2438998d4e8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINING SETUP DETAILS \n",
    "\"\"\"\n",
    "\n",
    "# Mean Squared Error (MSE) as Loss function\n",
    "criterion_mse = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Calculates the Mean Absolute Error (MAE) between predictions and targets\n",
    "def calculate_mae(preds, targets):\n",
    "    return torch.mean(torch.abs(preds - targets))\n",
    "\n",
    "\n",
    "# Determine the device to use: Use CUDA if available; otherwise, fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = TimeSeriesTransformer(input_size, output_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dropout_p).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fd103e5-edae-458c-8420-0b35bce1c732",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FUNCTION FOR MODEL TRAINING \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, criterion, dataloader, device):\n",
    "    \n",
    "    model.train()  # Set the model to training mode, which enables dropout and batch normalization layers\n",
    "\n",
    "    epoch_loss = 0.0  # Initialize total loss for the epoch\n",
    "    epoch_mae = 0.0  # Initialize total mean absolute error for the epoch\n",
    "    \n",
    "    for input_batch, target_batch_values in dataloader:\n",
    "        \n",
    "        # Move input and target data to the specified device (GPU or CPU)\n",
    "        src = input_batch.to(device)  # Prepare source sequence for model input\n",
    "        tgt = target_batch_values.to(device)  # Prepare target sequence for comparison with model output\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients before each backward pass\n",
    "        \n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(src, tgt)\n",
    "\n",
    "        # Ensure output dimensions are correct, especially for single-item batches\n",
    "        if outputs.shape[0] == 1:\n",
    "            outputs = outputs.squeeze(0)  # Remove singleton dimension if batch size is 1\n",
    "        elif outputs.shape[0] != tgt.shape[0]:\n",
    "            # Check for dimension mismatch and raise an error if found\n",
    "            raise ValueError(f\"Output and target batch sizes do not match: {outputs.shape[0]} != {tgt.shape[0]}\")\n",
    "\n",
    "        # Compute the loss between the model's outputs and the target values\n",
    "        loss = criterion(outputs, tgt)\n",
    "        \n",
    "        loss.backward()  # Compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()  # Update model parameters based on gradients\n",
    "\n",
    "        # Accumulate total loss and MAE for the epoch\n",
    "        epoch_loss += loss.item()  # Sum up batch loss\n",
    "        epoch_mae += calculate_mae(outputs, tgt).item()  # Sum up batch mean absolute error\n",
    "\n",
    "    # Calculate average loss and MAE across all batches\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_mae = epoch_mae / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_mae\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81cf6c6e-848f-49d1-a6d7-9e4ba88c473c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FUNCTION FOR MODEL VALIDATION \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validate_model(model, criterion, dataloader, device):\n",
    "    \n",
    "    model.eval()  # Switch the model to evaluation mode (disables dropout and batch normalization)\n",
    "\n",
    "    epoch_loss = 0.0  # Initialize total loss for the epoch\n",
    "    epoch_mae = 0.0  # Initialize total mean absolute error for the epoch\n",
    "\n",
    "    # Disable gradient computation to speed up the process and reduce memory usage\n",
    "    with torch.no_grad():\n",
    "        for input_batch, target_batch_values in dataloader:\n",
    "            \n",
    "            # Move input and target data to the specified device (GPU or CPU)\n",
    "            src = input_batch.to(device)  # Prepare source sequence for model input\n",
    "            tgt = target_batch_values.to(device)  # Prepare target sequence for comparison with model output\n",
    "\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(src, tgt)\n",
    "\n",
    "            # Check the shape of the outputs to ensure they match the target's shape\n",
    "            if outputs.shape[0] == 1:\n",
    "                outputs = outputs.squeeze(0)  # If batch size is 1, remove singleton dimension\n",
    "            elif outputs.shape[0] != tgt.shape[0]:\n",
    "                # If output and target batch sizes do not match, raise an error\n",
    "                raise ValueError(f\"Output and target batch sizes do not match: {outputs.shape[0]} != {tgt.shape[0]}\")\n",
    "\n",
    "            # Calculate the loss and mean absolute error for the batch\n",
    "            loss = criterion(outputs, tgt)\n",
    "\n",
    "            # Accumulate the loss and MAE for all batches\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_mae += calculate_mae(outputs, tgt).item()\n",
    "\n",
    "    # Calculate average loss and MAE across all batches\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_mae = epoch_mae / len(dataloader)\n",
    "\n",
    "    # Return the average loss and MAE for this validation run\n",
    "    return avg_loss, avg_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ed44488-2052-415a-8a35-fc169ba570fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "FUNCTION FOR MODEL EVALUATION\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, dataloader, device):\n",
    "    \n",
    "    model.eval()  # Switch the model to evaluation mode, disabling dropout and batch normalization for consistent predictions\n",
    "\n",
    "    epoch_loss = 0.0  # Initialize total loss for the evaluation\n",
    "    epoch_mae = 0.0  # Initialize total mean absolute error for the evaluation\n",
    "\n",
    "    all_predictions = []  # List to store all predictions across batches\n",
    "    all_targets = []  # List to store all target values across batches\n",
    "    \n",
    "    \n",
    "\n",
    "    with torch.no_grad():  # Context manager to turn off gradient computation, saving memory and computations\n",
    "        \n",
    "        for input_batch, target_batch_values in dataloader:\n",
    "            src = input_batch.to(device)  # Move input batch to the specified device\n",
    "            tgt = target_batch_values.to(device)  # Move target batch to the specified device\n",
    "\n",
    "            outputs = model(src, tgt)  # Forward pass: compute model's predictions\n",
    "\n",
    "            # Check if the output shape matches the target shape and adjust if necessary\n",
    "            if outputs.shape[0] == 1:\n",
    "                outputs = outputs.squeeze(0)  # Remove unnecessary dimension if batch size is 1\n",
    "            elif outputs.shape[0] != tgt.shape[0]:\n",
    "                # Ensure the predicted batch size matches the target batch size\n",
    "                raise ValueError(f\"Output and target batch sizes do not match: {outputs.shape[0]} != {tgt.shape[0]}\")\n",
    "            \n",
    "\n",
    "            loss = criterion(outputs, tgt)  # Calculate loss for the current batch\n",
    "            epoch_loss += loss.item()  # Accumulate loss over the epoch\n",
    "            epoch_mae += calculate_mae(outputs, tgt).item()  # Accumulate MAE over the epoch\n",
    "\n",
    "            all_predictions.append(outputs.cpu().numpy())  # Store predictions (move to CPU and convert to NumPy array)\n",
    "            all_targets.append(tgt.cpu().numpy())  # Store targets similarly\n",
    "            \n",
    "\n",
    "    # Calculate average loss and MAE for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_mae = epoch_mae / len(dataloader)\n",
    "\n",
    "    # Concatenate all batch predictions and targets into single arrays\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Return the average loss, MAE, and the complete sets of predictions and targets\n",
    "    return avg_loss, avg_mae, all_predictions, all_targets\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
